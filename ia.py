"""
Syst√®me de d√©tection d'EPI (√âquipements de Protection Individuelle)
avec YOLO et description en langage naturel via LLM
"""

import cv2
import numpy as np
import requests
import base64
from pathlib import Path
from typing import List, Dict, Tuple
import json

class EPIDetectionSystem:
    def __init__(self, ollama_url: str = "http://localhost:11434", 
                 model_name: str = "llama3.2-vision:latest",
                 yolo_model_path: str = None):
        """
        Initialise le syst√®me de d√©tection d'EPI
        
        Args:
            ollama_url: URL du serveur Ollama
            model_name: Nom du mod√®le Ollama (llama3.2-vision, llava, etc.)
            yolo_model_path: Chemin vers le mod√®le YOLO personnalis√© (optionnel)
        """
        self.ollama_url = ollama_url
        self.model_name = model_name
        
        # V√©rifier la connexion √† Ollama
        try:
            response = requests.get(f"{ollama_url}/api/tags")
            if response.status_code == 200:
                print(f"‚úì Connect√© √† Ollama sur {ollama_url}")
                models = response.json().get('models', [])
                print(f"  Mod√®les disponibles: {[m['name'] for m in models]}")
            else:
                print(f"‚ö† Ollama accessible mais r√©ponse inattendue")
        except requests.exceptions.ConnectionError:
            print(f"‚ö† Impossible de se connecter √† Ollama sur {ollama_url}")
            print("  Assurez-vous qu'Ollama est lanc√©: ollama serve")
        
        # Classes d'EPI √† d√©tecter
        self.epi_classes = [
            'casque', 'gilet_haute_visibilite', 'lunettes_protection',
            'gants', 'chaussures_securite', 'masque', 'harnais',
            'bouchons_oreilles', 'personne'
        ]
        
        # Initialisation de YOLO (YOLOv8 via ultralytics)
        try:
            from ultralytics import YOLO
            if yolo_model_path:
                self.model = YOLO(yolo_model_path)
            else:
                # Mod√®le YOLOv8 pr√©-entra√Æn√© (√† fine-tuner pour les EPI)
                self.model = YOLO('yolov8n.pt')
            print("‚úì Mod√®le YOLO charg√© avec succ√®s")
        except ImportError:
            print("‚ö† ultralytics non install√©. Installez avec: pip install ultralytics")
            self.model = None
    
    def detect_epi(self, image_path: str, conf_threshold: float = 0.5) -> Tuple[np.ndarray, List[Dict]]:
        """
        D√©tecte les EPI sur une image
        
        Args:
            image_path: Chemin vers l'image
            conf_threshold: Seuil de confiance minimum
            
        Returns:
            image_annotee: Image avec les d√©tections annot√©es
            detections: Liste des d√©tections avec leurs informations
        """
        if self.model is None:
            raise RuntimeError("Mod√®le YOLO non initialis√©")
        
        # Chargement de l'image
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Impossible de charger l'image: {image_path}")
        
        # D√©tection avec YOLO
        results = self.model(image, conf=conf_threshold)
        
        # Extraction des d√©tections
        detections = []
        for result in results:
            boxes = result.boxes
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                conf = float(box.conf[0])
                cls = int(box.cls[0])
                class_name = result.names[cls]
                
                detections.append({
                    'class': class_name,
                    'confidence': conf,
                    'bbox': [int(x1), int(y1), int(x2), int(y2)]
                })
        
        # Annotation de l'image
        image_annotee = results[0].plot()
        
        return image_annotee, detections
    
    def analyze_epi_compliance(self, detections: List[Dict]) -> Dict:
        """
        Analyse la conformit√© des EPI d√©tect√©s
        
        Args:
            detections: Liste des d√©tections
            
        Returns:
            Analyse de conformit√©
        """
        epi_detected = {}
        persons_detected = 0
        
        for det in detections:
            class_name = det['class']
            if class_name == 'personne' or 'person' in class_name.lower():
                persons_detected += 1
            else:
                if class_name not in epi_detected:
                    epi_detected[class_name] = 0
                epi_detected[class_name] += 1
        
        # Analyse basique
        analysis = {
            'personnes_detectees': persons_detected,
            'epi_detectes': epi_detected,
            'total_epi': len([d for d in detections if d['class'] != 'personne']),
            'detections_brutes': detections
        }
        
        return analysis
    
    def encode_image_to_base64(self, image_path: str) -> str:
        """Encode une image en base64 pour Ollama"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    
    def query_ollama(self, prompt: str, image_path: str = None) -> str:
        """
        Interroge Ollama avec ou sans image
        
        Args:
            prompt: Prompt texte
            image_path: Chemin vers l'image (optionnel, pour mod√®les vision)
            
        Returns:
            R√©ponse du mod√®le
        """
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": False
        }
        
        # Ajout de l'image si fournie (pour mod√®les vision comme llava ou llama3.2-vision)
        if image_path:
            base64_image = self.encode_image_to_base64(image_path)
            payload["images"] = [base64_image]
        
        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=120  # 2 minutes timeout
            )
            
            if response.status_code == 200:
                return response.json()['response']
            else:
                return f"Erreur Ollama: {response.status_code} - {response.text}"
        
        except Exception as e:
            return f"Erreur lors de la requ√™te Ollama: {str(e)}"
    
    def generate_natural_description(self, 
                                     image_path: str, 
                                     detections: List[Dict],
                                     analysis: Dict,
                                     use_vision: bool = True) -> str:
        """
        G√©n√®re une description en langage naturel avec Ollama
        
        Args:
            image_path: Chemin vers l'image
            detections: D√©tections YOLO
            analysis: Analyse de conformit√©
            use_vision: Utiliser un mod√®le vision (llava, llama3.2-vision)
            
        Returns:
            Description en langage naturel
        """
        # Pr√©paration du contexte
        detection_summary = json.dumps(analysis, indent=2, ensure_ascii=False)
        
        if use_vision:
            # Utilisation d'un mod√®le vision local
            prompt = f"""Tu es un expert en s√©curit√© au travail sp√©cialis√© dans l'analyse d'EPI (√âquipements de Protection Individuelle).

Analyse cette image de chantier/lieu de travail et les d√©tections automatiques suivantes :

{detection_summary}

Fournis une description professionnelle en fran√ßais incluant :
1. Le contexte g√©n√©ral de la sc√®ne
2. Les personnes pr√©sentes et leur √©quipement
3. Les EPI port√©s (casque, gilet, gants, lunettes, etc.)
4. Les EPI manquants ou non conformes
5. Une √©valuation globale de la conformit√© s√©curit√©
6. Des recommandations si n√©cessaire

Sois pr√©cis, concis et professionnel. R√©ponds UNIQUEMENT en fran√ßais."""
            
            response = self.query_ollama(prompt, image_path)
        
        else:
            # Utilisation sans vision (bas√© uniquement sur les d√©tections)
            prompt = f"""Tu es un expert en s√©curit√© au travail.

Analyse les d√©tections suivantes d'EPI (√âquipements de Protection Individuelle) :

{detection_summary}

Fournis un rapport professionnel en fran√ßais incluant :
1. R√©sum√© des personnes et EPI d√©tect√©s
2. √âvaluation de la conformit√© s√©curit√©
3. Points positifs
4. Points d'am√©lioration ou EPI manquants
5. Recommandations

Sois pr√©cis et professionnel. R√©ponds UNIQUEMENT en fran√ßais."""
            
            response = self.query_ollama(prompt)
        
        return response
    
    def process_image(self, 
                     image_path: str, 
                     output_path: str = None,
                     use_vision: bool = True) -> Dict:
        """
        Pipeline complet : d√©tection + analyse + description
        
        Args:
            image_path: Chemin vers l'image d'entr√©e
            output_path: Chemin pour sauvegarder l'image annot√©e
            use_vision: Utiliser GPT-4 Vision
            
        Returns:
            R√©sultats complets
        """
        print(f"üîç Analyse de l'image: {image_path}")
        
        # 1. D√©tection avec YOLO
        print("üìä D√©tection des EPI avec YOLO...")
        image_annotee, detections = self.detect_epi(image_path)
        
        # 2. Analyse de conformit√©
        print("‚úÖ Analyse de conformit√©...")
        analysis = self.analyze_epi_compliance(detections)
        
        # 3. G√©n√©ration de la description en langage naturel
        print("üí¨ G√©n√©ration de la description avec GPT...")
        description = self.generate_natural_description(
            image_path, detections, analysis, use_vision
        )
        
        # 4. Sauvegarde de l'image annot√©e
        if output_path:
            cv2.imwrite(output_path, image_annotee)
            print(f"üíæ Image annot√©e sauvegard√©e: {output_path}")
        
        return {
            'image_annotee': image_annotee,
            'detections': detections,
            'analyse': analysis,
            'description_naturelle': description
        }


# ============================================================================
# Exemple d'utilisation
# ============================================================================

def main():
    """Exemple d'utilisation du syst√®me"""
    
    # Configuration
    IMAGE_PATH = "images1.jpg"  # Votre image de test
    OUTPUT_PATH = "resultat_detection.jpg"
    
    # Initialisation du syst√®me avec Ollama
    system = EPIDetectionSystem(
        ollama_url="http://localhost:11434",
        model_name="llama3.2-vision:latest"  # ou "llava:latest", "llama3.2:latest"
    )
    
    # Traitement de l'image
    try:
        results = system.process_image(
            image_path=IMAGE_PATH,
            output_path=OUTPUT_PATH,
            use_vision=True  # True pour mod√®le vision, False pour texte seul
        )
        
        # Affichage des r√©sultats
        print("\n" + "="*70)
        print("üìã RAPPORT D'ANALYSE EPI")
        print("="*70)
        print(f"\nüî¢ Statistiques:")
        print(f"   ‚Ä¢ Personnes d√©tect√©es: {results['analyse']['personnes_detectees']}")
        print(f"   ‚Ä¢ Total EPI d√©tect√©s: {results['analyse']['total_epi']}")
        print(f"\nüéØ EPI identifi√©s:")
        for epi, count in results['analyse']['epi_detectes'].items():
            print(f"   ‚Ä¢ {epi}: {count}")
        
        print(f"\nüìù DESCRIPTION D√âTAILL√âE:")
        print("-" * 70)
        print(results['description_naturelle'])
        print("="*70)
        
        # Affichage de l'image (optionnel)
        # cv2.imshow("Detection EPI", results['image_annotee'])
        # cv2.waitKey(0)
        # cv2.destroyAllWindows()
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")


if __name__ == "__main__":
    # Instructions d'installation
    print("""
    üì¶ Packages requis:
    pip install ultralytics opencv-python pillow requests
    
    üîß Installation d'Ollama:
    1. T√©l√©charger Ollama: https://ollama.ai/download
    2. Lancer Ollama: ollama serve
    3. T√©l√©charger un mod√®le vision:
       ollama pull llama3.2-vision:latest
       # ou
       ollama pull llava:latest
       # ou pour texte seul (plus l√©ger):
       ollama pull llama3.2:latest
    
    üìù Mod√®les Ollama recommand√©s:
    - llama3.2-vision:latest (11B) - Excellent pour l'analyse d'image, fran√ßais OK
    - llava:latest (7B) - Bon compromis, multilingue
    - llama3.2:latest (3B) - L√©ger, texte seul, bon fran√ßais
    - llama3.1:8b - Tr√®s bon en fran√ßais, texte seul
    
    üí° Comparaison des mod√®les vision:
    - llama3.2-vision: Meilleure compr√©hension, plus lent (~11GB)
    - llava: Plus rapide, bon compromis (~4.5GB)
    
    üìù Notes importantes:
    1. Le mod√®le YOLOv8 de base d√©tecte des personnes mais pas les EPI sp√©cifiques
    2. Pour une d√©tection pr√©cise des EPI, il faut fine-tuner YOLO sur un dataset d'EPI
    3. Ollama tourne 100% en local, aucun co√ªt ni limite d'API !
    
    üéØ Pour am√©liorer les performances:
    - Fine-tuner YOLOv8 sur un dataset d'EPI annot√©
    - Utiliser llama3.2-vision pour une analyse d'image plus pr√©cise
    - Ajuster les prompts selon vos besoins sp√©cifiques
    """)
    
    # D√©commenter pour lancer
    main()